#// Logstash configuration file to ingest custom json file
#// Last Updated Date: Nov 19, 2019
#//
#// Usage Instructions:
#// Follow the wiki article for installation and usage Instructions.
#// https://github.com/Azure/Azure-Sentinel/wiki/Ingest-Custom-Logs-LogStash
#//
#// Parser Notes:
#// 1. Make sure the log type name is specified as alpha characters- no digits or special characters allowed.
#//
input{
s3 {
access_key_id => "S3 ACCESS ID"
secret_access_key => "S3 ACCESS KEY"
bucket => "cisco-managed-us-east-1"
# Use below if cisco is managing the S3 logs output 
# prefix => "uniqueciscoaccountname/dnslogs"
}
}
filter {
    csv {
    separator => ","
    columns => [ "Timestamp", "Most Granular Identity", "Identities", "InternalIp", "ExternalIp", "Action", "QueryType", "ResponseCode", "Domain", "Categories" ]
    }
}
output {
    azure_loganalytics {
        customer_id => "LOG ANALYTICS WORKSPACE ID"
        shared_key => "LOG ANALYTICS KEY"
        log_type => "ciscoumdns"
		flush_items => 10
        flush_interval_time => 5
        codec => "json"
    }
    # for debug
    stdout { codec => rubydebug }
}
